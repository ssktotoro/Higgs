import sys
import os
import theano
import pylearn2
#import pylearn2.datasets.physics
import pylearn2.training_algorithms.sgd
#import pylearn2.space
import pylearn2.models.mlp as mlp
import pylearn2.train
import numpy as np
from pylearn2.datasets.dense_design_matrix import DenseDesignMatrix
import pylearn2.termination_criteria
import pylearn2.costs.mlp.dropout

def init_train():
    # Initialize train object.

    save_path = '/home/kevin/Downloads/tryhard.pkl'
    data_train = np.loadtxt( 'training.csv', delimiter=',', skiprows=1, converters={32: lambda x:int(x=='s'.encode('utf-8')) } )
    rng = np.random.RandomState(42)
    r =np.random.rand(data_train.shape[0])
    X_train = data_train[:,1:31][r<.7]
    y_train = data_train[:,32].reshape((-1,1))[r<.7]
    W_train = data_train[:,31][r<.7]
    X_valid = data_train[:,1:31][r>=.7]
    y_valid = data_train[:,32].reshape((-1,1))[r>=.7]
    W_valid = data_train[:,31][r>=.7]
    # Dataset

    benchmark = 1

    nvis = 30
    data_test = np.loadtxt( 'test.csv', delimiter=',', skiprows=1 )
    X_test = data_test[:,1:31]
    train_matrix = DenseDesignMatrix(X=X_train, y=y_train)
    valid_matrix = DenseDesignMatrix(X=X_valid, y=y_valid)
    test_matrix = DenseDesignMatrix(X=X_test)
    # Parameters
    momentum_saturate = 200
    
    # Model
    model = pylearn2.models.mlp.MLP(layers=[mlp.Tanh(
                                                layer_name='h0',
                                                dim=300,
                                                istdev=.1),
                                            mlp.Tanh(
                                                layer_name='h1',
                                                dim=300,
                                                istdev=.05),
                                            mlp.Tanh(
                                                layer_name='h2',
                                                dim=300,
                                                istdev=.05),
                                            mlp.Tanh(
                                                layer_name='h3',
                                                dim=300,
                                                istdev=.05),
                                            mlp.Sigmoid(
                                                layer_name='y',
                                                dim=1,
                                                istdev=.001)
                                           ],
                                    nvis=nvis
                                    )

    # Algorithm
    algorithm = pylearn2.training_algorithms.sgd.SGD(
                    batch_size=100, # If changed, change learning rate!
                    learning_rate=.05, # In dropout paper=10 for gradient averaged over batch. Depends on batchsize.
                    init_momentum=.9,
                    monitoring_dataset = {'train' : train_matrix,
                                          'valid' : valid_matrix
                                          },
                    termination_criterion=pylearn2.termination_criteria.Or(criteria=[
                                            pylearn2.termination_criteria.MonitorBased(
                                                channel_name="valid_objective",
                                                prop_decrease=0.00001,
                                                N=40),
                                            pylearn2.termination_criteria.EpochCounter(
                                                max_epochs=momentum_saturate)
                                            ]),
                    cost = pylearn2.costs.mlp.dropout.Dropout(
                        input_include_probs={'h0':1., 'y':0.5},
                        input_scales={ 'h0': 1., 'y':2.}),

                    update_callbacks=pylearn2.training_algorithms.sgd.ExponentialDecay(
                                        decay_factor=1.0000002, # Decreases by this factor every batch. (1/(1.000001^8000)^100
                                        min_lr=.000001
                                        )
                )
    # Extensions
    extensions=[
        #pylearn2.train_extensions.best_params.MonitorBasedSaveBest(channel_name='train_y_misclass',save_path=save_path)
        pylearn2.training_algorithms.learning_rule.MomentumAdjustor(
            start=0,
            saturate=momentum_saturate,
            final_momentum=.99 # Dropout=.5->.99 over 500 epochs.
            )
        ]
    # Train
    train = pylearn2.train.Train(dataset=train_matrix,
                                 model=model,
                                 algorithm=algorithm,
                                 extensions=extensions,
                                 save_path=save_path,
                                 save_freq=100)
    return train
    
def train(mytrain):
    # Execute training loop.
    debug = False
    logfile = os.path.splitext(mytrain.save_path)[0] + '.log'
    print 'Using=%s' % theano.config.device # Can use gpus.
    print 'Writing to %s' % logfile
    print 'Writing to %s' % mytrain.save_path
    sys.stdout = open(logfile, 'w')
    mytrain.main_loop()


if __name__=='__main__':
    # Initialize and train.
    mytrain = init_train()
    train(mytrain)
